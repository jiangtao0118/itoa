package com.wisdom.spark.streaming.test

import com.wisdom.spark.common.util.SparkContextUtil
import org.apache.log4j.Logger
import org.apache.spark.sql.hive.HiveContext

/**
  * Created by wisdom on 2017/6/12.
  */
object Hivetest {

  val logger = Logger.getLogger(this.getClass)

  def main(args: Array[String]): Unit = {
    val sc = SparkContextUtil.getInstance()
    //    新建HiveContext对象
    val hiveCtx = new HiveContext(sc)
    UpdateHiveInput(hiveCtx)
  }

  def UpdateHiveInput(hiveContext: HiveContext) : Unit = {
    val table = hiveContext.sql("select * from hist_opm.opm_db limit 10")
    //val list = table.map(row => println(row))
    val len = table.collect().toList
    if (len.size == 0 ) { logger.warn("没有连上hive")}
    else len.map(row => println(row))
  }

}
