package com.wisdom.spark.streaming.thread

import com.wisdom.spark.common.util.{ConnPoolUtil2, ItoaPropertyUtil, SparkContextUtil}
import com.wisdom.spark.streaming.bean.AlarmConfiguration
import com.wisdom.spark.streaming.dao.AlarmDao
import org.apache.log4j.Logger
import org.apache.spark.sql.hive.HiveContext

/**
  * Created by wisdom on 2017/4/28.
  *
  * 动态阈值更新程序
  * 注：运行本程序需要将ItoaPropertyUtil中设置
  * var mlPath = "ml_properties.properties"
  * var etlPath = "etl_properties.properties"
  * var streamPath = "streaming_properties.properties"
  * 注意配置项中连接池最大连接数，推荐：2
  */
object UpdateThreshold {
  @transient
  //日志实例
  val logger = Logger.getLogger(this.getClass)
  //获取数据库连接
  val conn = ConnPoolUtil2.getConn()
  //  新建AlarmDao对象
  val alarmDao = new AlarmDao
  //  配置文件
  val props = ItoaPropertyUtil.getProperties()

  def main(args: Array[String]) {
    //公共方法：获取SparkContext
    val sc = SparkContextUtil.getInstance()
    //    新建HiveContext对象
    val hiveCtx = new HiveContext(sc)
    //更新网络动态阈值
    updateNcoThreshold(hiveCtx)
    //    更新指标规则配置关系表
    alarmDao.updateRCrel(conn)
    //释放连接
    ConnPoolUtil2.releaseCon(conn)
    //    停止程序
    sc.stop()
  }

  //更新网络动态阈值
  private def updateNcoThreshold(hiveCtx: HiveContext): Unit = {
    //查询Hive，统计出节点、告警时刻、指标名和指标值
    val lastoccurrence = (System.currentTimeMillis() / 1000L) - 600
    //    sql:查询出目标时间区间内的所有数据，并做时间戳转换（unixtime转换成hh:m0/hh:mm5的格式）
    val tempTable = hiveCtx.sql("select concat(substring(from_unixtime(lastoccurrence),12,4),(case when substring(from_unixtime(lastoccurrence),16,1) < '5' then '0' else '5' end)) as alarmTime," +
      " * from hist_ncoperf.reporter_status where length(trim(mibvalue)) > 0 and lastoccurrence < " + lastoccurrence)
    //    注册临时表
    tempTable.registerTempTable("tempNcoperf")
    logger.warn("~~~~~~~~~~~~~~~~~~~~~~~~ncoperf.reporter_status注册临时表结束~~~~~~~~~~~~~~~~~~~~~·")
    //    sql:按照字段node,alarmTime,alertgroup,devvendor进行分组，将同一alarmTime的mibvalue进行列转行，用逗号分隔
    val threshold_table = hiveCtx.sql("select node,alarmTime,alertgroup,devvendor,concat_ws(',',collect_list(concat(mibvalue))) as mibvalue " +
      "from tempNcoperf  group by node,alarmTime,alertgroup,devvendor")
    //RDD重分区分区
    val partitions = props.getProperty("kafka.data.partitions").toInt
    threshold_table.repartition(partitions)
    //缓存RDD
    threshold_table.persist()
    logger.warn("~~~~~~~~~~~~~~~~~~~~~~RDD缓存结束~~~~~~~~~~~~~~~~~~~~~~~~")
    //    计算DataFrame每一行数据中mibvalue的平均值和方差
    val alarmRulesDF = threshold_table.map(row => {
      //统计字符串形式的数组，求出平均值和方差
      def ARRstdev(arrDbl: Array[Double]): statistic = {
        //        平均值
        val avg = arrDbl.sum / arrDbl.length
        //        方差
        var sum = 0.0
        for (i <- arrDbl) {
          sum += math.pow(i - avg, 2)
        }
        val stdev = math.sqrt(sum / (arrDbl.length - 1))
        //        返回值statistic（均值，方差）
        statistic(avg, stdev)
      }

      val mibvalues = row.getString(4).split(",").map(a => a.toDouble)
      //      预测值阈值：mibvalues平均值
      val mid_threshold = ARRstdev(mibvalues).avg
      //      预测值下限阈值：mibvalues平均值-3倍方差
      val low_threshold = mid_threshold - 3 * ARRstdev(mibvalues).stdev
      //      预测值上限阈值：mibvalues平均值+3倍方差
      val high_threshold = mid_threshold + 3 * ARRstdev(mibvalues).stdev
      //      主机名
      val hostname = row.getString(0)
      //      时刻00:05
      val alarmTime = row.getString(1)
      //      指标名
      val predIndexName = row.getString(2)
      //      告警信息描述
      val confDesc = "网络指标" + predIndexName + "告警阈值配置"
      //      计算结果封装AlarmConfiguration
      val ac: AlarmConfiguration = new AlarmConfiguration()
      ac.setSysName("reporter_status")
      ac.setHostName(hostname)
      ac.setIndexTyp("00")
      ac.setAlarmTime(alarmTime)
      ac.setPredIndexName(predIndexName)
      ac.setConfDesc(confDesc)
      ac.setConfMidValue(mid_threshold.toString)
      ac.setConfLowValue(low_threshold.toString)
      ac.setConfHighValue(high_threshold.toString)
      ac
    })
    //    删除t_alarm_configuration中sysName="reporter_status"的所有条目
    alarmDao.delAlarmConf("reporter_status", conn)
    logger.warn("**** 开始批量保存告警阈值... ===> ")
    //    保存阈值配置信息到t_alarm_configuration中
    alarmRulesDF.foreachPartition(itera => {
      val conn = ConnPoolUtil2.getConn()
      alarmDao.saveAlarmConf(itera.toList, conn)
      ConnPoolUtil2.releaseCon(conn)
    })
  }

  //  用于保存mibvalue均值方差的class
  case class statistic(avg: Double, stdev: Double)

}
